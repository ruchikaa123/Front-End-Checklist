{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chest x ray",
      "provenance": [],
      "authorship_tag": "ABX9TyO0xkC9piSfmPPHi+YjhWfn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruchikaa123/Front-End-Checklist/blob/master/chest_x_ray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5-LUCS9Sl3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2cddbda-1f34-46f1-a576-381500e35d37"
      },
      "source": [
        "!wget http://www.dropbox.com/s/tlxserrdhe240lu/archive.zip"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-07-04 07:31:00--  https://www.dropbox.com/s/tlxserrdhe240lu/archive.zip\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/tlxserrdhe240lu/archive.zip [following]\n",
            "URL transformed to HTTPS due to an HSTS policy\n",
            "--2021-07-04 07:31:00--  https://www.dropbox.com/s/raw/tlxserrdhe240lu/archive.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucd13ebb73420c72de7bc2da3631.dl.dropboxusercontent.com/cd/0/inline/BRocnr_IofZSvxctHr1VueqsYX29Q8FDf7rnP_jIpEChL7S1d93fkAg0z_TaVG90b4AMrIegrPGLV3uyhjwQ4lMKcgnvLfUSWnc0BpjHYLnmHiNJfIT4BXkwx-m5KGRcHULchqVW9fUMS5TxJJmYSu9f/file# [following]\n",
            "--2021-07-04 07:31:00--  https://ucd13ebb73420c72de7bc2da3631.dl.dropboxusercontent.com/cd/0/inline/BRocnr_IofZSvxctHr1VueqsYX29Q8FDf7rnP_jIpEChL7S1d93fkAg0z_TaVG90b4AMrIegrPGLV3uyhjwQ4lMKcgnvLfUSWnc0BpjHYLnmHiNJfIT4BXkwx-m5KGRcHULchqVW9fUMS5TxJJmYSu9f/file\n",
            "Resolving ucd13ebb73420c72de7bc2da3631.dl.dropboxusercontent.com (ucd13ebb73420c72de7bc2da3631.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n",
            "Connecting to ucd13ebb73420c72de7bc2da3631.dl.dropboxusercontent.com (ucd13ebb73420c72de7bc2da3631.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BRopG9hKVxPpsiJm_eO91BeQCN0iGgezZK70xviXrxKAx0XWp_Am503-fjQ7PwbeyVBQUqJnpLaTGY06eXR3WaJ4gZjpR1uxM0nDMyEbX3uNYrhqNj6uxgOm6ZjaPW8t2cFx6IEHKIHtPw32wNEwvVqNOpOp9I5TAF3sWwV9rX5TpD_9CeWbmo_EE88rISV-hygRfKjLSdCjeroVOY0uVDcurCOshScmJqag1hR8NXPn7nzmB6KdItD14SRQI36lnGOA0H9sDZ8R_IWRoMQvM1Hu1QiEVAzwvb816EBUK1W_auoXANM1aPeSkR2TyvFi__JfsVvEviHwJ1Vr6Y_J-ZdVLzke7c86uCx0wX1aJdRDlhmPjZy1Kx0KJCIEo2WpZqc/file [following]\n",
            "--2021-07-04 07:31:00--  https://ucd13ebb73420c72de7bc2da3631.dl.dropboxusercontent.com/cd/0/inline2/BRopG9hKVxPpsiJm_eO91BeQCN0iGgezZK70xviXrxKAx0XWp_Am503-fjQ7PwbeyVBQUqJnpLaTGY06eXR3WaJ4gZjpR1uxM0nDMyEbX3uNYrhqNj6uxgOm6ZjaPW8t2cFx6IEHKIHtPw32wNEwvVqNOpOp9I5TAF3sWwV9rX5TpD_9CeWbmo_EE88rISV-hygRfKjLSdCjeroVOY0uVDcurCOshScmJqag1hR8NXPn7nzmB6KdItD14SRQI36lnGOA0H9sDZ8R_IWRoMQvM1Hu1QiEVAzwvb816EBUK1W_auoXANM1aPeSkR2TyvFi__JfsVvEviHwJ1Vr6Y_J-ZdVLzke7c86uCx0wX1aJdRDlhmPjZy1Kx0KJCIEo2WpZqc/file\n",
            "Reusing existing connection to ucd13ebb73420c72de7bc2da3631.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1237072214 (1.2G) [application/zip]\n",
            "Saving to: ‘archive.zip.1’\n",
            "\n",
            "archive.zip.1       100%[===================>]   1.15G   131MB/s    in 8.9s    \n",
            "\n",
            "2021-07-04 07:31:10 (132 MB/s) - ‘archive.zip.1’ saved [1237072214/1237072214]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XrA_7Vcsowj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5322849d-cab2-4bf9-bfca-27b313e70c4d"
      },
      "source": [
        "!unzip -q \"archive.zip\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace chest_xray/__MACOSX/._chest_xray? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJzbkbqVuG9d"
      },
      "source": [
        "import tensorflow as tf   #used to build deep learning model and data processing pipelines\n",
        "import numpy as np        #for fast numerical operations\n",
        "import matplotlib.pyplot as plt    #for plotting model training and evaluation matrix\n",
        "from pathlib import Path            # used to play around with path and directories\n",
        "\n",
        "\n",
        "tf.random.set_seed(4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9yg12Alu5Lj"
      },
      "source": [
        "train_path = Path(\"chest_xray/train/\")\n",
        "validation_path = Path(\"chest_xray/test\")\n",
        "test_path = Path(\"chest_xray/val\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7Bz937rvTht"
      },
      "source": [
        "#collecting all the paths inside \"normal\" and \"pneumonia\" folder of the above paths\n",
        "\n",
        "train_image_paths = train_path.glob(\"*/*\")\n",
        "val_image_paths = validation_path.glob(\"*/*\")\n",
        "\n",
        "#output is a generator object\n",
        "print(train_image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q8YsS77jwaS0"
      },
      "source": [
        "#convert gnerator object to list of element \n",
        "\n",
        "train_image_paths = list(train_image_paths)\n",
        "val_image_paths = list(val_image_paths)\n",
        "\n",
        "#now the output are \"posixpath\" objects\n",
        "print(train_image_paths[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2i82vgS0jGQ"
      },
      "source": [
        "# Convert Posix paths to normal strings\n",
        "train_image_paths = list(map(lambda x : str(x) , train_image_paths))\n",
        "val_image_paths = list(map(lambda x : str(x) , val_image_paths)) \n",
        "\n",
        "print(train_image_paths[:3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIY2fkxw1Hs6"
      },
      "source": [
        "# Collect Length for Training and Validation Datasets\n",
        "train_dataset_length = len(train_image_paths)\n",
        "val_dataset_length = len(val_image_paths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY6OMh7e1dHe"
      },
      "source": [
        "# Every Image has Label in its path , so lets slice it \n",
        "LABELS = {'NORMAL' : 0 , 'PNEUMONIA' : 1}\n",
        "INV_LABELS = {0 : 'NORMAL', 1 : 'PNEUMONIA'}\n",
        "\n",
        "def get_label(path : str) -> int:\n",
        "    return LABELS[path.split(\"/\")[-2]]\n",
        "\n",
        "train_labels = list(map(lambda x : get_label(x) , train_image_paths))\n",
        "val_labels = list(map(lambda x : get_label(x) , val_image_paths))\n",
        "\n",
        "print(train_labels[:3])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhjGnIqz7BI4"
      },
      "source": [
        " #Now we have all training, validation image paths and their respective labels \n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Function used for Transformation\n",
        "def load_and_transform(image , label , train = True):\n",
        "    image = tf.io.read_file(image)\n",
        "    image = tf.io.decode_jpeg(image , channels = 3)\n",
        "    image = tf.image.resize(image , [224 , 224] , method=\"nearest\")\n",
        "    if train:\n",
        "        image = tf.image.random_flip_left_right(image)\n",
        "    return image , label\n",
        "\n",
        "# Function used to Create a Tensorflow Data Object\n",
        "def get_dataset(paths , labels , train = True):\n",
        "    image_paths = tf.convert_to_tensor(paths)\n",
        "    labels = tf.convert_to_tensor(labels)\n",
        "\n",
        "    image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "    label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
        "\n",
        "    dataset = tf.data.Dataset.zip((image_dataset , label_dataset)).shuffle(1000)\n",
        "\n",
        "    dataset = dataset.map(lambda image , label : load_and_transform(image , label , train))\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.shuffle(2048)\n",
        "    dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSXffg5-71g0"
      },
      "source": [
        "#function used to create a tensorflow data object\n",
        "\n",
        "def get_dataset(paths , labels , train = True):\n",
        "  image_paths = tf.convert_to_tensor(paths)\n",
        "  labels = tf.convert_to_tensor(labels)\n",
        "\n",
        "  image_dataset = tf.data.Dataset.from_tensor_slices(image_paths)\n",
        "  label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
        "\n",
        "  dataset = tf.data.Dataset.zip((image_dataset , label_dataset)).shuffle(1000)\n",
        "\n",
        "  dataset = dataset.map(lambda image , label : load_and_transform(image , label , train))\n",
        "  dataset = dataset.repeat()\n",
        "  dataset = dataset.shuffle(2048)\n",
        "  dataset = dataset.batch(BATCH_SIZE)\n",
        "\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK2AXGoZ-Wyb"
      },
      "source": [
        " #creating train dataset object and verifying it \n",
        "\n",
        "%time train_dataset = get_dataset(train_image_paths, train_labels)\n",
        "\n",
        "image , label = next(iter(train_dataset))\n",
        "print(image.shape)\n",
        "print(label.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlZQp-qy_Mxa"
      },
      "source": [
        "#view a sampe train images\n",
        "print(INV_LABELS[label[0].numpy()])\n",
        "\n",
        "plt.imshow(image[0].numpy().reshape(224 , 224 , 3))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Re2QNNxhNShE"
      },
      "source": [
        "\n",
        "%time val_dataset = get_dataset(val_image_paths, val_labels, train = False)\n",
        "\n",
        "image , label = next(iter(val_dataset))\n",
        "print(image.shape)\n",
        "print(label.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAQe03VRNn0X"
      },
      "source": [
        "# View a sample Validation Image\n",
        "print(INV_LABELS[label[0].numpy()])\n",
        "plt.imshow(image[0].numpy().reshape(224 , 224 , 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9w2EtTtmP7Wt"
      },
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": []
    }
  ]
}